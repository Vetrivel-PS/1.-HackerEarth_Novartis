{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timing Libraries :\n",
    "import time\n",
    "\n",
    "# Warning Libraries :\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Scientific and Data Manipulation Libraries :\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import gc\n",
    "import os\n",
    "\n",
    "# NLP Libraries :\n",
    "import nltk\n",
    "from nltk.tokenize                    import word_tokenize\n",
    "from nltk                             import pos_tag\n",
    "from nltk.corpus                      import wordnet as wn\n",
    "from nltk.corpus                      import stopwords\n",
    "from nltk.stem                        import WordNetLemmatizer\n",
    "from collections                      import defaultdict\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# ML Libraries :\n",
    "from sklearn.externals                import joblib\n",
    "from sklearn.preprocessing            import LabelEncoder, OneHotEncoder \n",
    "from sklearn.preprocessing            import StandardScaler, MinMaxScaler, Normalizer, RobustScaler, MaxAbsScaler\n",
    "from sklearn.feature_extraction.text  import TfidfVectorizer\n",
    "from sklearn.model_selection          import KFold, StratifiedKFold, train_test_split, cross_val_score\n",
    "from sklearn.linear_model             import MultiTaskElasticNet, ElasticNet, Lasso, RidgeClassifier, SGDClassifier, PassiveAggressiveClassifier, LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors                import KNeighborsClassifier\n",
    "from sklearn.svm                      import SVC\n",
    "from sklearn.tree                     import DecisionTreeClassifier\n",
    "from sklearn.ensemble                 import VotingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes              import MultinomialNB, GaussianNB, ComplementNB\n",
    "from sklearn.discriminant_analysis    import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics                  import f1_score, accuracy_score, precision_score , recall_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.decomposition            import IncrementalPCA\n",
    "from statsmodels.stats.proportion     import proportion_confint\n",
    "\n",
    "# Boosting Algorithms :\n",
    "from xgboost                          import XGBClassifier\n",
    "from catboost                         import CatBoostClassifier\n",
    "from lightgbm                         import LGBMClassifier\n",
    "\n",
    "# Data Visualization Packages :\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Location path :\n",
    "import os\n",
    "os.chdir(\"C:/Users/LD196YS/Desktop/0.                          Winning_Kaggle/0. HackerEarth Hackathon/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "\n",
    "train = pd.read_csv('1. Data/Train.csv')\n",
    "train.drop([\"INCIDENT_ID\"],axis = 1,inplace=True)\n",
    "\n",
    "test = pd.read_csv('1. Data/Test.csv')\n",
    "test_ID = test[\"INCIDENT_ID\"]\n",
    "test.drop([\"INCIDENT_ID\"],axis = 1,inplace=True)\n",
    "\n",
    "sub = pd.read_csv('1. Data/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23856 entries, 0 to 23855\n",
      "Data columns (total 17 columns):\n",
      "DATE                23856 non-null object\n",
      "X_1                 23856 non-null int64\n",
      "X_2                 23856 non-null int64\n",
      "X_3                 23856 non-null int64\n",
      "X_4                 23856 non-null int64\n",
      "X_5                 23856 non-null int64\n",
      "X_6                 23856 non-null int64\n",
      "X_7                 23856 non-null int64\n",
      "X_8                 23856 non-null int64\n",
      "X_9                 23856 non-null int64\n",
      "X_10                23856 non-null int64\n",
      "X_11                23856 non-null int64\n",
      "X_12                23674 non-null float64\n",
      "X_13                23856 non-null int64\n",
      "X_14                23856 non-null int64\n",
      "X_15                23856 non-null int64\n",
      "MULTIPLE_OFFENSE    23856 non-null int64\n",
      "dtypes: float64(1), int64(15), object(1)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_Null_Values</th>\n",
       "      <th>Test_Null_Values</th>\n",
       "      <th>Data_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MULTIPLE_OFFENSE</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_12</th>\n",
       "      <td>182</td>\n",
       "      <td>127.0</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Train_Null_Values  Test_Null_Values Data_Type\n",
       "DATE                              0               0.0    object\n",
       "MULTIPLE_OFFENSE                  0               NaN     int64\n",
       "X_1                               0               0.0     int64\n",
       "X_10                              0               0.0     int64\n",
       "X_11                              0               0.0     int64\n",
       "X_12                            182             127.0   float64\n",
       "X_13                              0               0.0     int64\n",
       "X_14                              0               0.0     int64\n",
       "X_15                              0               0.0     int64\n",
       "X_2                               0               0.0     int64\n",
       "X_3                               0               0.0     int64\n",
       "X_4                               0               0.0     int64\n",
       "X_5                               0               0.0     int64\n",
       "X_6                               0               0.0     int64\n",
       "X_7                               0               0.0     int64\n",
       "X_8                               0               0.0     int64\n",
       "X_9                               0               0.0     int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d1=train.isnull().sum().to_frame().rename(columns={0: \"Train_Null_Values\"})\n",
    "d2=test.isnull().sum().to_frame().rename(columns={0: \"Test_Null_Values\"})\n",
    "d3=train.dtypes.to_frame().rename(columns={0: \"Data_Type\"})\n",
    "table = pd.concat([d1, d2,d3], axis=1)\n",
    "display(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23856, 17)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23846, 17)\n"
     ]
    }
   ],
   "source": [
    "# dropping duplicate values \n",
    "train.drop_duplicates(keep=False,inplace=True) \n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.ffill(axis = 0)\n",
    "# train = train.bfill(axis = 0)\n",
    "\n",
    "test = test.ffill(axis = 0)\n",
    "# test = test.bfill(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_Null_Values</th>\n",
       "      <th>Test_Null_Values</th>\n",
       "      <th>Data_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MULTIPLE_OFFENSE</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_12</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Train_Null_Values  Test_Null_Values Data_Type\n",
       "DATE                              0               0.0    object\n",
       "MULTIPLE_OFFENSE                  0               NaN     int64\n",
       "X_1                               0               0.0     int64\n",
       "X_10                              0               0.0     int64\n",
       "X_11                              0               0.0     int64\n",
       "X_12                              0               1.0   float64\n",
       "X_13                              0               0.0     int64\n",
       "X_14                              0               0.0     int64\n",
       "X_15                              0               0.0     int64\n",
       "X_2                               0               0.0     int64\n",
       "X_3                               0               0.0     int64\n",
       "X_4                               0               0.0     int64\n",
       "X_5                               0               0.0     int64\n",
       "X_6                               0               0.0     int64\n",
       "X_7                               0               0.0     int64\n",
       "X_8                               0               0.0     int64\n",
       "X_9                               0               0.0     int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d1=train.isnull().sum().to_frame().rename(columns={0: \"Train_Null_Values\"})\n",
    "d2=test.isnull().sum().to_frame().rename(columns={0: \"Test_Null_Values\"})\n",
    "d3=train.dtypes.to_frame().rename(columns={0: \"Data_Type\"})\n",
    "table = pd.concat([d1, d2,d3], axis=1)\n",
    "display(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DATE', 'X_1', 'X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7', 'X_8', 'X_9',\n",
       "       'X_10', 'X_11', 'X_12', 'X_13', 'X_14', 'X_15', 'MULTIPLE_OFFENSE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[[ 'DATE', 'X_1', 'X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7',\n",
    "       'X_8', 'X_9', 'X_10', 'X_11', 'X_12', 'X_13', 'X_14', 'X_15']]\n",
    "y_train = train['MULTIPLE_OFFENSE']\n",
    "y_train = y_train.to_frame()\n",
    "\n",
    "X_test = test[[ 'DATE', 'X_1', 'X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7',\n",
    "       'X_8', 'X_9', 'X_10', 'X_11', 'X_12', 'X_13', 'X_14', 'X_15' ]]\n",
    "\n",
    "# # Binning :\n",
    "# X_train['age'] = pd.cut( x=X_train['age'], bins=[20, 29, 39, 49], labels=['20', '30', '40'] )\n",
    "# X_test['age']  = pd.cut(x=X_test['age'], bins=[20, 29, 39, 49], labels=['20', '30', '40'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15903, 16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(24, 6))\n",
    "# plt.subplot(121)\n",
    "# sns.distplot(train[\"avg_training_score\"])\n",
    "# plt.subplot(122)\n",
    "# train[\"avg_training_score\"] = np.log1p(train[\"avg_training_score\"])\n",
    "# sns.distplot(train[\"avg_training_score\"])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_encoding( encoding_strategy , encoding_data , encoding_columns ):\n",
    "    \n",
    "    if encoding_strategy == \"LabelEncoding\":\n",
    "        print(\"IF LabelEncoding\")\n",
    "        Encoder = LabelEncoder()\n",
    "        for column in encoding_columns :\n",
    "            print(\"column\",column )\n",
    "            encoding_data[ column ] = Encoder.fit_transform(tuple(encoding_data[ column ]))\n",
    "        \n",
    "    elif encoding_strategy == \"OneHotEncoding\":\n",
    "        print(\"ELIF OneHotEncoding\")\n",
    "        encoding_data = pd.get_dummies(encoding_data)\n",
    "        \n",
    "    elif encoding_strategy == \"TargetEncoding\":\n",
    "        print(\"ELIF TargetEncoding\")\n",
    "        ## Code Coming soon\n",
    "        print(\"TargetEncoding\")\n",
    "\n",
    "    else :\n",
    "        print(\"ELSE OneHotEncoding\")\n",
    "        encoding_data = pd.get_dummies(encoding_data)\n",
    "        \n",
    "    dtypes_list =['float64','float32','int64','int32']\n",
    "    encoding_data.astype( dtypes_list[0] ).dtypes\n",
    "    \n",
    "    return encoding_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IF LabelEncoding\n",
      "column DATE\n",
      "IF LabelEncoding\n",
      "column DATE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23846, 16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15903, 16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>X_5</th>\n",
       "      <th>X_6</th>\n",
       "      <th>X_7</th>\n",
       "      <th>X_8</th>\n",
       "      <th>X_9</th>\n",
       "      <th>X_10</th>\n",
       "      <th>X_11</th>\n",
       "      <th>X_12</th>\n",
       "      <th>X_13</th>\n",
       "      <th>X_14</th>\n",
       "      <th>X_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92</td>\n",
       "      <td>29</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5267</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>236</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103</td>\n",
       "      <td>142</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4426</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110</td>\n",
       "      <td>93</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3703</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>249</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3622</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112</td>\n",
       "      <td>29</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DATE  X_1  X_2  X_3  X_4  X_5  X_6  X_7  X_8  X_9  X_10  X_11  X_12  X_13  \\\n",
       "0  1032    0   36   34    2    1    5    6    1    6     1   174   1.0    92   \n",
       "1  5267    1   37   37    0    0   11   17    1    6     1   236   1.0   103   \n",
       "2  4426    0    3    2    3    5    1    0    2    3     1   174   1.0   110   \n",
       "3  3703    0   33   32    2    1    7    1    1    6     1   249   1.0    72   \n",
       "4  3622    0   33   32    2    1    8    3    0    5     1   174   0.0   112   \n",
       "\n",
       "   X_14  X_15  \n",
       "0    29    36  \n",
       "1   142    34  \n",
       "2    93    34  \n",
       "3    29    34  \n",
       "4    29    43  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>X_5</th>\n",
       "      <th>X_6</th>\n",
       "      <th>X_7</th>\n",
       "      <th>X_8</th>\n",
       "      <th>X_9</th>\n",
       "      <th>X_10</th>\n",
       "      <th>X_11</th>\n",
       "      <th>X_12</th>\n",
       "      <th>X_13</th>\n",
       "      <th>X_14</th>\n",
       "      <th>X_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72</td>\n",
       "      <td>119</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1220</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6891</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4491</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112</td>\n",
       "      <td>87</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7926</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112</td>\n",
       "      <td>93</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DATE  X_1  X_2  X_3  X_4  X_5  X_6  X_7  X_8  X_9  X_10  X_11  X_12  X_13  \\\n",
       "0    83    0   30   35    7    3    6    4    0    5     1   174   NaN    72   \n",
       "1  1220    0   44   44    1    3    7    1    4    6     1   316   0.0    12   \n",
       "2  6891    0   34   33    3    5    2    7    3    0     1   316   1.0    72   \n",
       "3  4491    7    3    2    3    5    9    8    0    5     1   174   1.0   112   \n",
       "4  7926    0    7    8    7    3    2    7    1    5     1   174   0.0   112   \n",
       "\n",
       "   X_14  X_15  \n",
       "0   119    23  \n",
       "1    29    34  \n",
       "2     0    34  \n",
       "3    87    34  \n",
       "4    93    43  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoding_columns  = [ \"DATE\" ]\n",
    "encoding_strategy = [ \"LabelEncoding\", \"OneHotEncoding\", \"TargetEncoding\", \"ELSE\" ]\n",
    "\n",
    "X_train_encode = data_encoding( encoding_strategy[0] , X_train , encoding_columns )\n",
    "X_test_encode =  data_encoding( encoding_strategy[0] , X_test  , encoding_columns )\n",
    "\n",
    "display(X_train_encode.shape)\n",
    "display(X_test_encode.shape)\n",
    "\n",
    "display(X_train_encode.head())\n",
    "display(X_test_encode.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_scaling( scaling_strategy , scaling_data , scaling_columns ):\n",
    "    \n",
    "    if    scaling_strategy ==\"RobustScaler\" :\n",
    "        scaling_data[scaling_columns] = RobustScaler().fit_transform(scaling_data[scaling_columns])\n",
    "        \n",
    "    elif  scaling_strategy ==\"StandardScaler\" :\n",
    "        scaling_data[scaling_columns] = StandardScaler().fit_transform(scaling_data[scaling_columns])\n",
    "        \n",
    "    elif  scaling_strategy ==\"MinMaxScaler\" :\n",
    "        scaling_data[scaling_columns] = MinMaxScaler().fit_transform(scaling_data[scaling_columns])\n",
    "        \n",
    "    elif  scaling_strategy ==\"MaxAbsScaler\" :\n",
    "        scaling_data[scaling_columns] = MaxAbsScaler().fit_transform(scaling_data[scaling_columns])\n",
    "        \n",
    "    else :  # If any other scaling send by mistake still perform Robust Scalar\n",
    "        scaling_data[scaling_columns] = RobustScaler().fit_transform(scaling_data[scaling_columns])\n",
    "    \n",
    "    return scaling_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23846, 16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15903, 16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>X_5</th>\n",
       "      <th>X_6</th>\n",
       "      <th>X_7</th>\n",
       "      <th>X_8</th>\n",
       "      <th>X_9</th>\n",
       "      <th>X_10</th>\n",
       "      <th>X_11</th>\n",
       "      <th>X_12</th>\n",
       "      <th>X_13</th>\n",
       "      <th>X_14</th>\n",
       "      <th>X_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.330017</td>\n",
       "      <td>-0.335925</td>\n",
       "      <td>0.735687</td>\n",
       "      <td>0.618785</td>\n",
       "      <td>-0.773555</td>\n",
       "      <td>-0.741818</td>\n",
       "      <td>-0.257957</td>\n",
       "      <td>0.289528</td>\n",
       "      <td>0.018727</td>\n",
       "      <td>0.789433</td>\n",
       "      <td>-0.218763</td>\n",
       "      <td>-0.354138</td>\n",
       "      <td>0.022551</td>\n",
       "      <td>0.245213</td>\n",
       "      <td>-1.008681</td>\n",
       "      <td>0.302579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.277142</td>\n",
       "      <td>0.359126</td>\n",
       "      <td>0.801297</td>\n",
       "      <td>0.816979</td>\n",
       "      <td>-1.452748</td>\n",
       "      <td>-1.251202</td>\n",
       "      <td>1.083838</td>\n",
       "      <td>3.123078</td>\n",
       "      <td>0.018727</td>\n",
       "      <td>0.789433</td>\n",
       "      <td>-0.218763</td>\n",
       "      <td>0.312219</td>\n",
       "      <td>0.022551</td>\n",
       "      <td>0.643755</td>\n",
       "      <td>1.600982</td>\n",
       "      <td>0.064116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.042013</td>\n",
       "      <td>-0.335925</td>\n",
       "      <td>-1.429435</td>\n",
       "      <td>-1.495276</td>\n",
       "      <td>-0.433959</td>\n",
       "      <td>1.295719</td>\n",
       "      <td>-1.152487</td>\n",
       "      <td>-1.256046</td>\n",
       "      <td>0.706812</td>\n",
       "      <td>-1.411786</td>\n",
       "      <td>-0.218763</td>\n",
       "      <td>-0.354138</td>\n",
       "      <td>0.022551</td>\n",
       "      <td>0.897372</td>\n",
       "      <td>0.469358</td>\n",
       "      <td>0.064116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.316387</td>\n",
       "      <td>-0.335925</td>\n",
       "      <td>0.538858</td>\n",
       "      <td>0.486657</td>\n",
       "      <td>-0.773555</td>\n",
       "      <td>-0.741818</td>\n",
       "      <td>0.189308</td>\n",
       "      <td>-0.998450</td>\n",
       "      <td>0.018727</td>\n",
       "      <td>0.789433</td>\n",
       "      <td>-0.218763</td>\n",
       "      <td>0.451939</td>\n",
       "      <td>0.022551</td>\n",
       "      <td>-0.479407</td>\n",
       "      <td>-1.008681</td>\n",
       "      <td>0.064116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.347126</td>\n",
       "      <td>-0.335925</td>\n",
       "      <td>0.538858</td>\n",
       "      <td>0.486657</td>\n",
       "      <td>-0.773555</td>\n",
       "      <td>-0.741818</td>\n",
       "      <td>0.412941</td>\n",
       "      <td>-0.483259</td>\n",
       "      <td>-0.669358</td>\n",
       "      <td>0.055694</td>\n",
       "      <td>-0.218763</td>\n",
       "      <td>-0.354138</td>\n",
       "      <td>-0.835101</td>\n",
       "      <td>0.969834</td>\n",
       "      <td>-1.008681</td>\n",
       "      <td>1.137199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DATE       X_1       X_2       X_3       X_4       X_5       X_6  \\\n",
       "0 -1.330017 -0.335925  0.735687  0.618785 -0.773555 -0.741818 -0.257957   \n",
       "1  0.277142  0.359126  0.801297  0.816979 -1.452748 -1.251202  1.083838   \n",
       "2 -0.042013 -0.335925 -1.429435 -1.495276 -0.433959  1.295719 -1.152487   \n",
       "3 -0.316387 -0.335925  0.538858  0.486657 -0.773555 -0.741818  0.189308   \n",
       "4 -0.347126 -0.335925  0.538858  0.486657 -0.773555 -0.741818  0.412941   \n",
       "\n",
       "        X_7       X_8       X_9      X_10      X_11      X_12      X_13  \\\n",
       "0  0.289528  0.018727  0.789433 -0.218763 -0.354138  0.022551  0.245213   \n",
       "1  3.123078  0.018727  0.789433 -0.218763  0.312219  0.022551  0.643755   \n",
       "2 -1.256046  0.706812 -1.411786 -0.218763 -0.354138  0.022551  0.897372   \n",
       "3 -0.998450  0.018727  0.789433 -0.218763  0.451939  0.022551 -0.479407   \n",
       "4 -0.483259 -0.669358  0.055694 -0.218763 -0.354138 -0.835101  0.969834   \n",
       "\n",
       "       X_14      X_15  \n",
       "0 -1.008681  0.302579  \n",
       "1  1.600982  0.064116  \n",
       "2  0.469358  0.064116  \n",
       "3 -1.008681  0.064116  \n",
       "4 -1.008681  1.137199  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>X_5</th>\n",
       "      <th>X_6</th>\n",
       "      <th>X_7</th>\n",
       "      <th>X_8</th>\n",
       "      <th>X_9</th>\n",
       "      <th>X_10</th>\n",
       "      <th>X_11</th>\n",
       "      <th>X_12</th>\n",
       "      <th>X_13</th>\n",
       "      <th>X_14</th>\n",
       "      <th>X_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.675947</td>\n",
       "      <td>-0.331491</td>\n",
       "      <td>0.346549</td>\n",
       "      <td>0.689163</td>\n",
       "      <td>0.913022</td>\n",
       "      <td>0.280919</td>\n",
       "      <td>-0.019072</td>\n",
       "      <td>-0.223796</td>\n",
       "      <td>-0.670686</td>\n",
       "      <td>0.066374</td>\n",
       "      <td>-0.286551</td>\n",
       "      <td>-0.353946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.479810</td>\n",
       "      <td>1.076998</td>\n",
       "      <td>-1.253620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.180836</td>\n",
       "      <td>-0.331491</td>\n",
       "      <td>1.265886</td>\n",
       "      <td>1.284127</td>\n",
       "      <td>-1.104130</td>\n",
       "      <td>0.280919</td>\n",
       "      <td>0.205598</td>\n",
       "      <td>-1.002121</td>\n",
       "      <td>2.048132</td>\n",
       "      <td>0.793841</td>\n",
       "      <td>-0.286551</td>\n",
       "      <td>1.171216</td>\n",
       "      <td>-1.109829</td>\n",
       "      <td>-2.662237</td>\n",
       "      <td>-0.994975</td>\n",
       "      <td>0.069446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.288621</td>\n",
       "      <td>-0.331491</td>\n",
       "      <td>0.609216</td>\n",
       "      <td>0.556949</td>\n",
       "      <td>-0.431746</td>\n",
       "      <td>1.299606</td>\n",
       "      <td>-0.917751</td>\n",
       "      <td>0.554530</td>\n",
       "      <td>1.368427</td>\n",
       "      <td>-3.570957</td>\n",
       "      <td>-0.286551</td>\n",
       "      <td>1.171216</td>\n",
       "      <td>0.031582</td>\n",
       "      <td>-0.479810</td>\n",
       "      <td>-1.662610</td>\n",
       "      <td>0.069446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.243532</td>\n",
       "      <td>4.625778</td>\n",
       "      <td>-1.426459</td>\n",
       "      <td>-1.492370</td>\n",
       "      <td>-0.431746</td>\n",
       "      <td>1.299606</td>\n",
       "      <td>0.654937</td>\n",
       "      <td>0.813972</td>\n",
       "      <td>-0.670686</td>\n",
       "      <td>0.066374</td>\n",
       "      <td>-0.286551</td>\n",
       "      <td>-0.353946</td>\n",
       "      <td>0.031582</td>\n",
       "      <td>0.975141</td>\n",
       "      <td>0.340297</td>\n",
       "      <td>0.069446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.739315</td>\n",
       "      <td>-0.331491</td>\n",
       "      <td>-1.163791</td>\n",
       "      <td>-1.095728</td>\n",
       "      <td>0.913022</td>\n",
       "      <td>0.280919</td>\n",
       "      <td>-0.917751</td>\n",
       "      <td>0.554530</td>\n",
       "      <td>0.009018</td>\n",
       "      <td>0.066374</td>\n",
       "      <td>-0.286551</td>\n",
       "      <td>-0.353946</td>\n",
       "      <td>-1.109829</td>\n",
       "      <td>0.975141</td>\n",
       "      <td>0.478428</td>\n",
       "      <td>1.151954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DATE       X_1       X_2       X_3       X_4       X_5       X_6  \\\n",
       "0 -1.675947 -0.331491  0.346549  0.689163  0.913022  0.280919 -0.019072   \n",
       "1 -1.180836 -0.331491  1.265886  1.284127 -1.104130  0.280919  0.205598   \n",
       "2  1.288621 -0.331491  0.609216  0.556949 -0.431746  1.299606 -0.917751   \n",
       "3  0.243532  4.625778 -1.426459 -1.492370 -0.431746  1.299606  0.654937   \n",
       "4  1.739315 -0.331491 -1.163791 -1.095728  0.913022  0.280919 -0.917751   \n",
       "\n",
       "        X_7       X_8       X_9      X_10      X_11      X_12      X_13  \\\n",
       "0 -0.223796 -0.670686  0.066374 -0.286551 -0.353946       NaN -0.479810   \n",
       "1 -1.002121  2.048132  0.793841 -0.286551  1.171216 -1.109829 -2.662237   \n",
       "2  0.554530  1.368427 -3.570957 -0.286551  1.171216  0.031582 -0.479810   \n",
       "3  0.813972 -0.670686  0.066374 -0.286551 -0.353946  0.031582  0.975141   \n",
       "4  0.554530  0.009018  0.066374 -0.286551 -0.353946 -1.109829  0.975141   \n",
       "\n",
       "       X_14      X_15  \n",
       "0  1.076998 -1.253620  \n",
       "1 -0.994975  0.069446  \n",
       "2 -1.662610  0.069446  \n",
       "3  0.340297  0.069446  \n",
       "4  0.478428  1.151954  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaling_strategy = [\"RobustScaler\", \"StandardScaler\",\"MinMaxScaler\",\"MaxAbsScaler\"]\n",
    "X_train_scale = data_scaling( scaling_strategy[1] , X_train_encode , X_train_encode.columns )\n",
    "X_test_scale = data_scaling( scaling_strategy [1] , X_test_encode , X_test_encode.columns )\n",
    "\n",
    "display(X_train_scale.shape)\n",
    "display(X_test_scale.shape)\n",
    "\n",
    "display(X_train_scale.head())\n",
    "display(X_test_scale.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.1_XGBoost_Version_33', '0.1_XGBoost_Version_33', '2.1_CatBoost_Version_10', '2.2_CatBoost_Version_10', '3.1_LightGBM_Version_1.1', '3.2_LightGBM_Version_2.1', '4.1_GradBoost']\n",
      "[XGBClassifier(base_score=0.2, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.1, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=494, n_jobs=None, num_parallel_tree=None,\n",
      "              objective='binary:logistic', random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=2.5, silent=True, subsample=0.7,\n",
      "              tree_method=None, updater='grow_histmaker',\n",
      "              validate_parameters=False, verbosity=None), XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=0.3,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=494, n_jobs=None, nthread=15, num_parallel_tree=None,\n",
      "              objective='binary:logistic', random_state=None, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=2.5, silent=True, subsample=1,\n",
      "              tree_method=None, validate_parameters=False, verbosity=None), <catboost.core.CatBoostClassifier object at 0x000001C9C2951BC8>, <catboost.core.CatBoostClassifier object at 0x000001C9C2951708>, LGBMClassifier(boosting_type='dart', class_weight=None, colsample_bytree=1.0,\n",
      "               importance_type='gain', learning_rate=0.15, max_bin=60,\n",
      "               max_depth=5, min_child_samples=20, min_child_weight=0.001,\n",
      "               min_split_gain=0.0, n_estimators=494, n_jobs=-1, num_leaves=300,\n",
      "               objective='binary', random_state=None, reg_alpha=0.0,\n",
      "               reg_lambda=0.0, scale_pos_weight=2.5, silent=True, subsample=1.0,\n",
      "               subsample_for_bin=200000, subsample_freq=2, verbosity=-1), LGBMClassifier(bagging_fraction=0.9, boosting_type='dart', class_weight=None,\n",
      "               colsample_bytree=1.0, feature_fraction=0.9,\n",
      "               importance_type='gain', learning_rate=0.15, max_bin=60,\n",
      "               max_depth=5, min_child_samples=20, min_child_weight=0.001,\n",
      "               min_split_gain=0.0, n_estimators=494, n_jobs=-1, num_leaves=300,\n",
      "               objective='binary', random_state=None, reg_alpha=0.0,\n",
      "               reg_lambda=0.0, scale_pos_weight=2.5, silent=True, subsample=1.0,\n",
      "               subsample_for_bin=200000, subsample_freq=2, verbosity=-1), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=5,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=4,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=0.7, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)]\n"
     ]
    }
   ],
   "source": [
    "Classifiers = {\n",
    "                 '1.1_XGBoost_Version_33'     : XGBClassifier(learning_rate =0.1, n_estimators=494, max_depth=5,subsample = 0.70, \n",
    "                                                              scale_pos_weight = 2.5,updater =\"grow_histmaker\",base_score  = 0.2,\n",
    "                                                              silent=True),\n",
    "    \n",
    "   '0.1_XGBoost_Version_33'     :  XGBClassifier(base_score=0.5, gamma=0.3, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
    "        missing=None, n_estimators=494, nthread=15,\n",
    "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
    "       scale_pos_weight=2.5,  silent=True, subsample=1),\n",
    "                 \n",
    "#                  '1.2_XGBoost_Version_34'     : XGBClassifier(learning_rate=0.1, n_estimators=494, max_depth=4, subsample=0.8,\n",
    "#                                                               scale_pos_weight=2.5,min_child_weight=7, gamma=0.4, nthread=4,  \n",
    "#                                                               colsample_bytree=0.8),\n",
    "    \n",
    "                 '2.1_CatBoost_Version_10': CatBoostClassifier(silent=True, learning_rate=0.15, n_estimators=494, subsample=0.085, max_depth=5, scale_pos_weight=2.5,\n",
    "                                                                 random_strength= None, \n",
    "                                                                                              min_data_in_leaf=None,max_bin =None,l2_leaf_reg=None,bagging_temperature=None,depth=None,model_size_reg=None,rsm=None,loss_function=None,border_count=None,feature_border_type=None,per_float_feature_quantization=None,                         \n",
    "                                                                                              input_borders=None,output_borders=None,fold_permutation_block=None,od_pval=None,od_wait=None,nan_mode=None,counter_calc_method=None,leaf_estimation_iterations=None,\n",
    "                                                                                              leaf_estimation_method=None,thread_count=None,verbose=None,logging_level=None,metric_period=None,ctr_leaf_count_limit=None,store_all_simple_ctr=None,\n",
    "                                                                                              max_ctr_complexity=None,has_time=None,allow_const_label=None,classes_count=None,class_weights=None,one_hot_max_size=None,name=None,ignored_features=None,train_dir=None,\n",
    "                                                                                              custom_loss=None,custom_metric=None,eval_metric=None,save_snapshot=None,snapshot_file=None,snapshot_interval=None,fold_len_multiplier=None,\n",
    "                                                                                              used_ram_limit=None,gpu_ram_part=None,allow_writing_files=None,final_ctr_computation_mode=None,approx_on_full_history=None,boosting_type=None,simple_ctr=None,combinations_ctr=None,per_feature_ctr=None,\n",
    "                                                                                              task_type=None,device_config=None,devices=None,bootstrap_type=None,sampling_unit=None,dev_score_calc_obj_block_size=None,num_boost_round=None,\n",
    "                                                                                              num_trees=None,colsample_bylevel=None,random_state=None,reg_lambda=None,objective=None,eta=None,gpu_cat_features_storage=None,data_partition=None,\n",
    "                                                                                              metadata=None,cat_features=None,min_child_samples=None,max_leaves=None,num_leaves=None,score_function=None,\n",
    "                                                                                              leaf_estimation_backtracking=None,ctr_history_unit=None,monotone_constraints=None,feature_weights=None,penalties_coefficient=None,first_feature_use_penalties=None,model_shrink_rate=None,\n",
    "                                                                                              model_shrink_mode=None,langevin=None,diffusion_temperature=None,boost_from_average=None,text_features=None,tokenizers=None,dictionaries=None,feature_calcers=None,text_processing=None),\n",
    "               \n",
    "                '2.2_CatBoost_Version_10': CatBoostClassifier(silent=True, learning_rate=0.15, n_estimators=494, subsample=0.085, max_depth=5, scale_pos_weight=2.5,\n",
    "                                                                 random_strength= 0.157, \n",
    "                                                                                              min_data_in_leaf=None,max_bin =None,l2_leaf_reg=None,bagging_temperature=None,depth=None,model_size_reg=None,rsm=None,loss_function=None,border_count=None,feature_border_type=None,per_float_feature_quantization=None,                         \n",
    "                                                                                              input_borders=None,output_borders=None,fold_permutation_block=None,od_pval=None,od_wait=None,nan_mode=None,counter_calc_method=None,leaf_estimation_iterations=None,\n",
    "                                                                                              leaf_estimation_method=None,thread_count=None,verbose=None,logging_level=None,metric_period=None,ctr_leaf_count_limit=None,store_all_simple_ctr=None,\n",
    "                                                                                              max_ctr_complexity=None,has_time=None,allow_const_label=None,classes_count=None,class_weights=None,one_hot_max_size=None,name=None,ignored_features=None,train_dir=None,\n",
    "                                                                                              custom_loss=None,custom_metric=None,eval_metric=None,save_snapshot=None,snapshot_file=None,snapshot_interval=None,fold_len_multiplier=None,\n",
    "                                                                                              used_ram_limit=None,gpu_ram_part=None,allow_writing_files=None,final_ctr_computation_mode=None,approx_on_full_history=None,boosting_type=None,simple_ctr=None,combinations_ctr=None,per_feature_ctr=None,\n",
    "                                                                                              task_type=None,device_config=None,devices=None,bootstrap_type=None,sampling_unit=None,dev_score_calc_obj_block_size=None,num_boost_round=None,\n",
    "                                                                                              num_trees=None,colsample_bylevel=None,random_state=None,reg_lambda=None,objective=None,eta=None,gpu_cat_features_storage=None,data_partition=None,\n",
    "                                                                                              metadata=None,cat_features=None,min_child_samples=None,max_leaves=None,num_leaves=None,score_function=None,\n",
    "                                                                                              leaf_estimation_backtracking=None,ctr_history_unit=None,monotone_constraints=None,feature_weights=None,penalties_coefficient=None,first_feature_use_penalties=None,model_shrink_rate=None,\n",
    "                                                                                              model_shrink_mode=None,langevin=None,diffusion_temperature=None,boost_from_average=None,text_features=None,tokenizers=None,dictionaries=None,feature_calcers=None,text_processing=None),\n",
    "#                 '3.1_LightGBM_Verion_WINNING': LGBMClassifier(boosting_type='dart',\n",
    "#                        max_depth=5, scale_pos_weight=2.5,\n",
    "#                        learning_rate=0.05,\n",
    "#                        n_estimators=5000,\n",
    "#                        min_child_weight=0.01,\n",
    "#                        colsample_bytree=0.5,\n",
    "#                        random_state=1994),\n",
    "               '3.1_LightGBM_Version_1.1' : LGBMClassifier(  subsample_freq = 2, objective =\"binary\",importance_type = \"gain\",verbosity = -1, max_bin = 60,num_leaves = 300,boosting_type = 'dart',learning_rate=0.15, n_estimators=494, max_depth=5, scale_pos_weight=2.5),\n",
    "               '3.2_LightGBM_Version_2.1' : LGBMClassifier(  bagging_fraction=0.9, feature_fraction=0.9, subsample_freq = 2, objective =\"binary\",importance_type = \"gain\",verbosity = -1, max_bin = 60,num_leaves = 300,boosting_type = 'dart',learning_rate=0.15, n_estimators=494, max_depth=5, scale_pos_weight=2.5),\n",
    "\n",
    "#  'feature_fraction': 0.5004666960515116,\n",
    "#  'lambda_l2': 0.022577930769472343,\n",
    "#  'min_data_in_leaf': 99,\n",
    "#  'num_leaves': 13\n",
    "    \n",
    "               '4.1_GradBoost'            : GradientBoostingClassifier(min_samples_split= 4,max_depth=5, n_estimators=1000, subsample=0.70)\n",
    "              }\n",
    "\n",
    "print( list(Classifiers.keys()) )\n",
    "print( list(Classifiers.values()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Public Leaderboard F1 Score : 0.533762057877814\n",
    "# -------------------------------------------------\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "#                                               ('XGBoost_Best_1', list(Classifiers.values())[0]), \n",
    "#                                               ('XGBoost_Best_2', list(Classifiers.values())[1]),\n",
    "                                              ('CatBoost_Best_1', list(Classifiers.values())[2]),\n",
    "                                              ('CatBoost_Best_2', list(Classifiers.values())[3]), \n",
    "                                              ('LightGBM_1', list(Classifiers.values())[4]),\n",
    "                                              ('LightGBM_2', list(Classifiers.values())[5]),\n",
    "                                             ], \n",
    "                                              voting='hard'\n",
    "#                                   ,weights=[5,5,5]\n",
    "                                 )\n",
    "\n",
    "# Public Leaderboard F1 Score : 0.513816280806572\n",
    "# -----------------------------------------------\n",
    "# ensemble_model = XGBClassifier    (   learning_rate =0.1, n_estimators=494, max_depth=5,subsample = 0.70, \n",
    "#                                       scale_pos_weight = 2.5,updater =\"grow_histmaker\",base_score  = 0.2,\n",
    "#                                       silent=True\n",
    "#                                   )\n",
    "# Public Leaderboard F1 Score : 0.5273311897106109\n",
    "# ------------------------------------------------\n",
    "# ensemble_model = CatBoostClassifier(  silent=True, learning_rate=0.15, n_estimators=494, subsample=0.085, \n",
    "#                                         max_depth=5, scale_pos_weight=2.5 \n",
    "#                                    )\n",
    "# Public Leaderboard F1 Score : 0.5196324143692564\n",
    "# -----------------------------------------------\n",
    "# ensemble_model = LGBMClassifier   (   subsample_freq = 2, objective =\"binary\",importance_type = \"gain\",verbosity = -1, \n",
    "#                                         max_bin = 60,num_leaves = 300,boosting_type = 'dart',\n",
    "#                                         learning_rate=0.15, n_estimators=494, max_depth=5, scale_pos_weight=2.5\n",
    "#                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble_model = list(Classifiers.values())[4]\n",
    "\n",
    "file_name = \"2_3_4_5\"\n",
    "model = ensemble_model.fit(X_train_scale,y_train)\n",
    "# Predicted_predictions_model = model.predict_proba( X_test_scale )[::,1]\n",
    "\n",
    "Predicted_predictions_model = model.predict( X_test_scale )\n",
    "\n",
    "predictions = [int(round(value)) for value in Predicted_predictions_model]\n",
    "Result_Promoted = pd.DataFrame({'INCIDENT_ID': test_ID, 'MULTIPLE_OFFENSE' : predictions})\n",
    "pd.DataFrame(Result_Promoted).to_csv(r\"1. Final Data/2. Output/Predicted_\"+file_name+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-47ffef4c871a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-21-47ffef4c871a>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    STOP !!!!\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "STOP !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up folds\n",
    "K = 10\n",
    "kf = KFold(n_splits = K, random_state = 294, shuffle = True)\n",
    "skf = StratifiedKFold(n_splits = K, random_state = 294, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_scale\n",
    "y = y_train\n",
    "\n",
    "X_test = X_test_scale\n",
    "y_valid_pred = 0*y\n",
    "y_test_pred = 0\n",
    "recall = 0\n",
    "result={}\n",
    "#specifying categorical variables indexes\n",
    "# cat_columns = [\"department\", \"region\", \"education\", \"gender\", \"recruitment_channel\"]\n",
    "#fitting catboost classifier model\n",
    "j=1\n",
    "\n",
    "model = ensemble_model\n",
    "\n",
    "# for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):  \n",
    "    \n",
    "    if j in [1,2,3,4,5,6,7,8,9,10]:\n",
    "        # Create data for this fold\n",
    "        y_train_cv, y_valid_cv = y.iloc[train_index], y.iloc[test_index]\n",
    "        X_train_cv, X_valid_cv = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        print( \"\\nFold \", j)\n",
    "        #print( \"\\nFold \", i)\n",
    "\n",
    "        # Run model for this fold\n",
    "    #     if OPTIMIZE_ROUNDS:\n",
    "    #         fit_model = model.fit( X_train_cv, y_train_cv, \n",
    "    #                                eval_set=[X_valid_cv, y_valid_cv]\n",
    "    # #                                use_best_model=True\n",
    "    #                              )\n",
    "    #         print( \"  N trees = \", model.tree_count_ )\n",
    "    #     else:\n",
    "\n",
    "        fit_model = model.fit( X_train_cv, y_train_cv )\n",
    "\n",
    "        # Generate validation predictions for this fold\n",
    "        pred = fit_model.predict(X_valid_cv)\n",
    "        y_valid_pred.iloc[test_index] = pred.reshape(-1,1)\n",
    "        print(recall_score(y_valid_cv,pred))\n",
    "        recall+=recall_score(y_valid_cv,pred)\n",
    "        # Accumulate test set predictions\n",
    "        y_test_pred += fit_model.predict(X_test)\n",
    "        result[j]=fit_model.predict(X_test)\n",
    "    j+=1\n",
    "results = y_test_pred / K  # Average test set predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(result)\n",
    "d = pd.DataFrame()\n",
    "for i in [1,2,3,4,5,6,7,8,9,10]:\n",
    "    d = pd.concat([d,pd.DataFrame(result[i])],axis=1)\n",
    "    \n",
    "# d.columns=['2','4','6','9','10']\n",
    "d.columns=['1','2','3','4','5','6','7','8','9','10']\n",
    "\n",
    "predictions = d.mode(axis=1)[0]\n",
    "file_name = \"10_CV.csv\"\n",
    "Result_Promoted = pd.DataFrame({'INCIDENT_ID': test_ID, 'MULTIPLE_OFFENSE' : predictions})\n",
    "pd.DataFrame(Result_Promoted).to_csv(r\"1. Final Data/2. Output/Predicted_\"+file_name+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_CV_train, X_CV_val, y_CV_train, y_val = train_test_split(X_train_scale, y_train, test_size=0.9, \n",
    "                                                    random_state=294,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_f1(y, t):\n",
    "    t = t.get_label()\n",
    "    y_bin = [1. if y_cont < 0.5 else 0. for y_cont in y]\n",
    "    return 'f1', f1_score(t, y_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "\n",
    "ensemble_model = XGBClassifier    (   learning_rate =0.1, n_estimators=10000, max_depth=5,subsample = 0.70, \n",
    "                                      scale_pos_weight = 2.5,updater =\"grow_histmaker\",base_score  = 0.2,\n",
    "                                      silent=True\n",
    "                                  )\n",
    "\n",
    "ensemble_model = ensemble_model.fit(\n",
    "                                    X_CV_train,  y_CV_train,\n",
    "                                    eval_metric=xgb_f1, \n",
    "                                    eval_set=[(X_CV_train,  y_CV_train), ( X_CV_val, y_val )], \n",
    "                                    verbose=True, \n",
    "                                    early_stopping_rounds = 100)\n",
    "\n",
    "best_estimators=ensemble_model.best_iteration\n",
    "\n",
    "print(best_estimators)\n",
    "\n",
    "ensemble_model = XGBClassifier(\n",
    "    \n",
    "    n_estimators = best_estimators,\n",
    "    \n",
    "    learning_rate =0.1, max_depth=5,subsample = 0.70, \n",
    "    scale_pos_weight = 2.5,updater =\"grow_histmaker\",base_score  = 0.2,\n",
    "    silent=True\n",
    "    )\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = XGBClassifier    (   \n",
    "                                      learning_rate =0.1, n_estimators=306, max_depth=5, subsample = 0.70, \n",
    "                                      scale_pos_weight = 2.5, updater =\"grow_histmaker\", base_score  = 0.2,\n",
    "                                      silent=True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OR - STOP !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Voting_ensemble_model = VotingClassifier(estimators=[\n",
    "                                              ('XGBoost_Best', list(Classifiers.values())[0]), \n",
    "                                              ('CatBoost_Best', list(Classifiers.values())[2]),\n",
    "                                              ('LightGBM_1', list(Classifiers.values())[4]),\n",
    "                                             ], \n",
    "                                              voting='soft',weights=[5,5,5.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ROUNDS = 1000\n",
    "OPTIMIZE_ROUNDS = True\n",
    "#LEARNING_RATE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X_train_scale\n",
    "# y = y_train\n",
    "# X_test = X_test_scale\n",
    "# y_valid_pred = 0*y\n",
    "# y_test_pred = 0\n",
    "# f1score = 0\n",
    "# result={}\n",
    "# #specifying categorical variables indexes\n",
    "# cat_columns = [\"department\", \"region\", \"education\", \"gender\", \"recruitment_channel\"]\n",
    "# #fitting catboost classifier model\n",
    "# j=1\n",
    "\n",
    "# # model = CatBoostClassifier(n_estimators=MAX_ROUNDS,verbose=False)\n",
    "# model = CatBoostClassifier(learning_rate=0.15, n_estimators=494, subsample=0.085, max_depth=5, scale_pos_weight=2.5,verbose=False)\n",
    "\n",
    "# for i, (train_index, test_index) in enumerate(kf.split(X_train_scale)):\n",
    "\n",
    "# #for train_index, test_index in skf.split(X, y):  \n",
    "#     # Create data for this fold\n",
    "#     y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
    "#     X_train, X_valid = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "#     print( \"\\nFold \", j)\n",
    "#     #print( \"\\nFold \", i)\n",
    "    \n",
    "#     # Run model for this fold\n",
    "#     if OPTIMIZE_ROUNDS:\n",
    "#         fit_model = model.fit( X_train, y_train, \n",
    "#                                eval_set=[X_valid, y_valid],cat_features=cat_columns,\n",
    "#                                use_best_model=True\n",
    "#                              )\n",
    "#         print( \"  N trees = \", model.tree_count_ )\n",
    "#     else:\n",
    "#         fit_model = model.fit( X_train, y_train,cat_features=cat_columns )\n",
    "        \n",
    "#     # Generate validation predictions for this fold\n",
    "#     pred = fit_model.predict(X_valid)\n",
    "#     y_valid_pred.iloc[test_index] = pred.reshape(-1)\n",
    "#     print(f1_score(y_valid,pred))\n",
    "#     f1score+=f1_score(y_valid,pred)\n",
    "#     # Accumulate test set predictions\n",
    "#     y_test_pred += fit_model.predict(X_test)\n",
    "#     result[j]=fit_model.predict(X_test)\n",
    "#     j+=1\n",
    "# results = y_test_pred / K  # Average test set predictions\n",
    "# print(f1score/5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
